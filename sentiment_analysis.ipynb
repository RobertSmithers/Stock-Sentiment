{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "altered-manor",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "This file attempts to gather tweets surrounding a specific pair of stocks. This is the second part in a two-part process of processing data.\n",
    "\n",
    "After data is collected for the time frame provided (with the post dates matching up), it can be fed into our model which we still need to make\n",
    "\n",
    "- textblob uses a Naive Bayes classifier trained on movie reviews to determine sentiment of some text. We use this in an attempt to estimate public sentiment on a given stock\n",
    "- ideally, we want to gather 6 things from this file for every day for each pair of stocks:\n",
    "\n",
    "| 1 | 2 | 3 | 4 | 5 | 6 |\n",
    "| --- | --- | --- | --- | --- | --- | \n",
    "| % tweets positive | % tweets negative | % tweets neutral | # likes among pos tweets | # likes among negative tweets | # likes among neutral tweets |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-turning",
   "metadata": {},
   "source": [
    "### Issues and concerns\n",
    "\n",
    "So... what issue did I run into that caused me great grief during this project?\n",
    "\n",
    "- Twitter's free API does not allow you to retrieve tweets beyond 7 days, as previously discussed\n",
    "- Twitter firehose is needed to do this, and that would cost a pretty penny, not to mention take some time to get set up\n",
    "\n",
    "Workaround?\n",
    "\n",
    "- Can currently only train data from the past week on our given stocks... not enough time for real training.\n",
    "- Perhaps we can look to reddit instead in the meantime?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "advised-tokyo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /opt/conda/lib/python3.8/site-packages (4.4.0)\n",
      "Requirement already satisfied: textblob in /opt/conda/lib/python3.8/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /opt/conda/lib/python3.8/site-packages (from textblob) (3.6.5)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.8/site-packages (from nltk>=3.1->textblob) (2021.11.10)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from nltk>=3.1->textblob) (4.56.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from nltk>=3.1->textblob) (1.0.0)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: requests<3,>=2.11.1 in /opt/conda/lib/python3.8/site-packages (from tweepy) (2.25.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.11.1->tweepy) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.11.1->tweepy) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.11.1->tweepy) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.11.1->tweepy) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib<2,>=1.0.0->tweepy) (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-magic",
   "metadata": {},
   "source": [
    "#### Gather our corpa of text for interpretation\n",
    "**Note:** We may want to come back to this and find a corpa more catered to stocks/a specific stock sector that we are looking at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "weird-travel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-centre",
   "metadata": {},
   "source": [
    "## Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "quarterly-receipt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @StockMKTNewz: Cloudflare $NET announced today it has acquired Zaraz \"a company that has developed technology to speed up and secure web‚Ä¶\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-886a2d9870d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;31m# calling main function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-886a2d9870d1>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTwitterClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m# calling function to get tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cloudflare'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-886a2d9870d1>\u001b[0m in \u001b[0;36mget_tweets\u001b[0;34m(self, query, count)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;31m# appending parsed tweet to tweets list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretweet_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;31m# if tweet has retweets, ensure that it is appended only once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparsed_tweet\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tweepy/mixins.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import re\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "from textblob import TextBlob\n",
    "from datetime import datetime, date, timezone\n",
    "\n",
    "from twitter_auth import API_KEY, API_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET, BEARER_TOKEN\n",
    "  \n",
    "class TwitterClient(object):\n",
    "    '''\n",
    "    Generic Twitter Class for sentiment analysis.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Class constructor or initialization method.\n",
    "        '''\n",
    "        # keys and tokens from the Twitter Dev Console\n",
    "        consumer_key = API_KEY\n",
    "        consumer_secret = API_SECRET\n",
    "        access_token = ACCESS_TOKEN\n",
    "        access_token_secret = ACCESS_TOKEN_SECRET\n",
    "  \n",
    "        # attempt authentication\n",
    "        try:\n",
    "            # create OAuthHandler object\n",
    "#             self.auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "            # set access token and secret\n",
    "#             self.auth.set_access_token(access_token, access_token_secret)\n",
    "            # create tweepy API object to fetch tweets\n",
    "#             self.api = tweepy.API(self.auth)\n",
    "            self.api = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
    "        except:\n",
    "            print(\"Error: Authentication Failed\")\n",
    "  \n",
    "    def clean_tweet(self, tweet):\n",
    "        '''\n",
    "        Utility function to clean tweet text by removing links, special characters\n",
    "        using simple regex statements.\n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "  \n",
    "    def get_tweet_sentiment(self, tweet):\n",
    "        '''\n",
    "        Utility function to classify sentiment of passed tweet\n",
    "        using textblob's sentiment method\n",
    "        '''\n",
    "        # create TextBlob object of passed tweet text\n",
    "        analysis = TextBlob(self.clean_tweet(tweet))\n",
    "        # set sentiment\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "  \n",
    "    def get_tweets(self, query, count = 10):\n",
    "        '''\n",
    "        Main function to fetch tweets and parse them.\n",
    "        '''\n",
    "        # empty list to store parsed tweets\n",
    "        tweets = []\n",
    "  \n",
    "#         try:\n",
    "        # call twitter api to fetch tweets\n",
    "        \n",
    "        # By default, search_tweets uses a \"mixed\" result_type, meaning we will get tweets\n",
    "        # that will be recently posted (in real time) AND popular tweets\n",
    "        \n",
    "        # Sadly, the start_time parameter also has a 7-day limit, so we are unable to limit our results to anything before then\n",
    "        \n",
    "        # The time that we are making our prediction, time t\n",
    "        # UTC Time (Union[datetime.datetime, str]) ‚Äì YYYY-MM-DDTHH:mm:ssZ\n",
    "        \n",
    "        end_time = datetime(2021, 12, 8, hour=16, minute=0, second=0, microsecond=0, tzinfo=timezone.utc).isoformat()\n",
    "        \n",
    "        # The time that we are beggining to look at our predictions, time t-window_size\n",
    "        # YYYY-MM-DDTHH:mm:ssZ\n",
    "        start_time = datetime(2021,12,3, hour=16, minute=0, second=0, microsecond=0, tzinfo=timezone.utc).isoformat()\n",
    "        \n",
    "        # Max results between 10 and 100\n",
    "        fetched_tweets = self.api.search_recent_tweets(query, max_results=count, start_time=start_time, end_time=end_time)\n",
    "\n",
    "        # tweet_fields = [created_at, text] \n",
    "        \n",
    "        \n",
    "        # parsing tweets one by one\n",
    "        for tweet in fetched_tweets[0]:\n",
    "            # empty dictionary to store required params of a tweet\n",
    "            parsed_tweet = {}\n",
    "\n",
    "            \n",
    "            print(tweet)\n",
    "            # saving text of tweet\n",
    "            parsed_tweet['text'] = tweet.text\n",
    "            # saving sentiment of tweet\n",
    "            parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text)\n",
    "\n",
    "            # appending parsed tweet to tweets list\n",
    "            if tweet.retweet_count > 0:\n",
    "                # if tweet has retweets, ensure that it is appended only once\n",
    "                if parsed_tweet not in tweets:\n",
    "                    tweets.append(parsed_tweet)\n",
    "            else:\n",
    "                tweets.append(parsed_tweet)\n",
    "\n",
    "        # return parsed tweets\n",
    "        return tweets\n",
    "  \n",
    "#         except Exception as e:\n",
    "#             # print error (if any)\n",
    "#             print(\"Error : \" + str(e))\n",
    "  \n",
    "def main():\n",
    "    # creating object of TwitterClient Class\n",
    "    api = TwitterClient()\n",
    "    # calling function to get tweets\n",
    "    tweets = api.get_tweets(query = 'Cloudflare', count = 10)\n",
    "    print(tweets)\n",
    "    \n",
    "    # picking positive tweets from tweets\n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive']\n",
    "    # percentage of positive tweets\n",
    "    print(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/len(tweets)))\n",
    "    # picking negative tweets from tweets\n",
    "    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative']\n",
    "    # percentage of negative tweets\n",
    "    print(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/len(tweets)))\n",
    "    # percentage of neutral tweets\n",
    "    print(\"Neutral tweets percentage: {} % \\\n",
    "        \".format(100*(len(tweets) -(len( ntweets )+len( ptweets)))/len(tweets)))\n",
    "\n",
    "    # printing first 5 positive tweets\n",
    "    print(\"\\n\\nPositive tweets:\")\n",
    "    for tweet in ptweets[:10]:\n",
    "        print(tweet['text'])\n",
    "\n",
    "    # printing first 5 negative tweets\n",
    "    print(\"\\n\\nNegative tweets:\")\n",
    "    for tweet in ntweets[:10]:\n",
    "        print(tweet['text'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # calling main function\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-error",
   "metadata": {},
   "source": [
    "### Shame on you Twitter\n",
    "But it's okay. We will go with our backup, Reddit!\n",
    "Plan B:\n",
    "\n",
    "| 1 | 2 | 3 | 4 | 5 | 6 |\n",
    "| --- | --- | --- | --- | --- | --- | \n",
    "| % posts positive | % posts negative | % posts neutral | # likes among pos posts | # likes among negative posts | # likes among neutral posts |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-badge",
   "metadata": {},
   "source": [
    "## Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "convinced-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta\n",
    "from textblob import TextBlob\n",
    "\n",
    "from reddit_auth import CLIENT_ID, CLIENT_SECRET, USERNAME, PASSWORD\n",
    "\n",
    "class RedditScraper(object):\n",
    "    def clean_post(self, post):\n",
    "            '''\n",
    "            Utility function to clean post text by removing links, special characters\n",
    "            using simple regex statements.\n",
    "            '''\n",
    "            return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", post).split())\n",
    "\n",
    "    def get_sentiment(self, post):\n",
    "        '''\n",
    "        Utility function to classify sentiment of passed post\n",
    "        using textblob's sentiment method\n",
    "        '''\n",
    "        # create TextBlob object of passed tweet text\n",
    "        analysis = TextBlob(self.clean_post(post))\n",
    "        # set sentiment\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "\n",
    "    # we use this function to convert responses to dataframes\n",
    "    def df_from_response(self, res):\n",
    "        # initialize temp dataframe for batch of data in response\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        # loop through each post pulled from res and append to df\n",
    "        for post in res.json()['data']['children']:\n",
    "    #         if post['data']['link_flair_css_class'] not in ['news', 'meme', 'discussion', 'dd']:\n",
    "    #             continue\n",
    "\n",
    "            df = df.append({\n",
    "    #             'subreddit': post['data']['subreddit'],\n",
    "                'title': post['data']['title'],\n",
    "                'selftext': post['data']['selftext'],\n",
    "                'upvote_ratio': post['data']['upvote_ratio'],\n",
    "    #             'ups': post['data']['ups'],\n",
    "    #             'downs': post['data']['downs'],\n",
    "                'score': post['data']['score'],\n",
    "    #             'link_flair_css_class': post['data']['link_flair_css_class'],\n",
    "                'created_utc': datetime.fromtimestamp(post['data']['created_utc']).strftime('%Y-%m-%d'), #T%H:%M:%SZ'),\n",
    "                'id': post['data']['id'],\n",
    "                'kind': post['kind']\n",
    "            }, ignore_index=True)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def parse_data(self, df):\n",
    "        df = df.sort_values(by=['created_utc'], ignore_index=True)\n",
    "        df['sentiment'] = df['title'].apply(self.get_sentiment)\n",
    "        return df\n",
    "    \n",
    "    def gather_data(self, ticker):\n",
    "        # authenticate API\n",
    "        client_auth = requests.auth.HTTPBasicAuth(CLIENT_ID, CLIENT_SECRET)\n",
    "        data = {\n",
    "            'grant_type': 'password',\n",
    "            'username': USERNAME,\n",
    "            'password': PASSWORD\n",
    "        }\n",
    "        headers = {'User-Agent': 'myBot/0.0.1'}\n",
    "\n",
    "        # send authentication request for OAuth token\n",
    "        res = requests.post('https://www.reddit.com/api/v1/access_token',\n",
    "                            auth=client_auth, data=data, headers=headers)\n",
    "        # extract token from response and format correctly\n",
    "        token = f\"bearer {res.json()['access_token']}\"\n",
    "        # update API headers with authorization (bearer token)\n",
    "        headers = {**headers, **{'Authorization': token}}\n",
    "\n",
    "        # initialize dataframe and parameters for pulling data in loop\n",
    "        data = pd.DataFrame()\n",
    "        params = {'limit': 100}\n",
    "\n",
    "        # loop through 10 times (returning 1K posts)\n",
    "        for i in range(10):\n",
    "            # make request\n",
    "            res = requests.get(\"https://oauth.reddit.com/r/wallstreetbets/search/?q=\" + ticker, #/hot\",\n",
    "                               headers=headers,\n",
    "                               params=params)\n",
    "\n",
    "            # get dataframe from response\n",
    "            new_df = self.df_from_response(res)\n",
    "\n",
    "            # Empty/no results, stop here\n",
    "            if new_df.shape[0] == 0:\n",
    "                break\n",
    "\n",
    "            # take the final row (oldest entry)\n",
    "            row = new_df.iloc[len(new_df)-1]\n",
    "            # create fullname\n",
    "            fullname = row['kind'] + '_' + row['id']\n",
    "            # add/update fullname in params\n",
    "            params['after'] = fullname\n",
    "\n",
    "            # append new_df to data\n",
    "            data = data.append(new_df, ignore_index=True)\n",
    "        \n",
    "        data = self.parse_data(data)\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "oriented-cookbook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "scraper = RedditScraper()\n",
    "data = scraper.gather_data(\"COHR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cognitive-disney",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>kind</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-04-17T13:14:42Z</td>\n",
       "      <td>1ilb8</td>\n",
       "      <td>t3</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>ALLIRA COHRS</td>\n",
       "      <td>0.50</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-11T16:58:42Z</td>\n",
       "      <td>f0ax0</td>\n",
       "      <td>t3</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>COHR, ENZ, BIIB, PWRM, PCLN - CRWEWallstreet.c...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-09-25T21:01:26Z</td>\n",
       "      <td>1n4ph5</td>\n",
       "      <td>t3</td>\n",
       "      <td>7.0</td>\n",
       "      <td></td>\n",
       "      <td>WIPO Approves 15 New Observers, Including DNDi...</td>\n",
       "      <td>0.82</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-09-25T21:18:42Z</td>\n",
       "      <td>1n4qvr</td>\n",
       "      <td>t3</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td>WIPO Approves 15 New Observers, Including DNDi...</td>\n",
       "      <td>0.63</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-10-26T18:04:28Z</td>\n",
       "      <td>3qb4zy</td>\n",
       "      <td>t3</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>Relationship between Blood Myostatin Levels an...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2021-11-29T11:54:46Z</td>\n",
       "      <td>r4u8n3</td>\n",
       "      <td>t3</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>$COHR Awaiting short signal. Algo Trading Idea...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2021-11-30T19:17:00Z</td>\n",
       "      <td>r5uymx</td>\n",
       "      <td>t3</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>$COHR Waiting for Short signal.</td>\n",
       "      <td>1.00</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>2021-12-03T18:14:00Z</td>\n",
       "      <td>r85dcd</td>\n",
       "      <td>t3</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>$COHR Awaiting Short Signal. Stock Trading Ide...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>2021-12-03T18:17:48Z</td>\n",
       "      <td>r85gfk</td>\n",
       "      <td>t3</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>$COHR Awaiting Short Signal. Stock Trading Ide...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2021-12-10T04:56:38Z</td>\n",
       "      <td>rd0pmj</td>\n",
       "      <td>t3</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>Stock Pattern Cup-and-Handle COHR on November ...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              created_utc      id kind  score selftext  \\\n",
       "0    2007-04-17T13:14:42Z   1ilb8   t3    0.0            \n",
       "1    2011-01-11T16:58:42Z   f0ax0   t3    0.0            \n",
       "2    2013-09-25T21:01:26Z  1n4ph5   t3    7.0            \n",
       "3    2013-09-25T21:18:42Z  1n4qvr   t3    2.0            \n",
       "4    2015-10-26T18:04:28Z  3qb4zy   t3    1.0            \n",
       "..                    ...     ...  ...    ...      ...   \n",
       "238  2021-11-29T11:54:46Z  r4u8n3   t3    1.0            \n",
       "239  2021-11-30T19:17:00Z  r5uymx   t3    1.0            \n",
       "240  2021-12-03T18:14:00Z  r85dcd   t3    1.0            \n",
       "241  2021-12-03T18:17:48Z  r85gfk   t3    1.0            \n",
       "242  2021-12-10T04:56:38Z  rd0pmj   t3    1.0            \n",
       "\n",
       "                                                 title  upvote_ratio sentiment  \n",
       "0                                         ALLIRA COHRS          0.50   neutral  \n",
       "1    COHR, ENZ, BIIB, PWRM, PCLN - CRWEWallstreet.c...          0.50   neutral  \n",
       "2    WIPO Approves 15 New Observers, Including DNDi...          0.82  positive  \n",
       "3    WIPO Approves 15 New Observers, Including DNDi...          0.63  positive  \n",
       "4    Relationship between Blood Myostatin Levels an...          1.00   neutral  \n",
       "..                                                 ...           ...       ...  \n",
       "238  $COHR Awaiting short signal. Algo Trading Idea...          1.00   neutral  \n",
       "239                    $COHR Waiting for Short signal.          1.00   neutral  \n",
       "240  $COHR Awaiting Short Signal. Stock Trading Ide...          1.00   neutral  \n",
       "241  $COHR Awaiting Short Signal. Stock Trading Ide...          1.00   neutral  \n",
       "242  Stock Pattern Cup-and-Handle COHR on November ...          1.00   neutral  \n",
       "\n",
       "[243 rows x 8 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "connected-delhi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2021, 4, 26)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date(2021,5,10)- timedelta(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "visible-accommodation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-05-03'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(date(2021,5,10) - timedelta(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "metallic-heritage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>kind</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2021-06-03T01:12:52Z</td>\n",
       "      <td>nr1dkn</td>\n",
       "      <td>t3</td>\n",
       "      <td>5367.0</td>\n",
       "      <td>I understand that most people in this thread i...</td>\n",
       "      <td>Beware of what AMC shorts are holding!</td>\n",
       "      <td>0.91</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2021-06-03T10:15:31Z</td>\n",
       "      <td>nr9zni</td>\n",
       "      <td>t3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>**Author**: u/Shark_Bones(**Karma:** 311078, *...</td>\n",
       "      <td>Are we headed for the Mother of All Crashes? H...</td>\n",
       "      <td>0.67</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2021-06-03T19:35:46Z</td>\n",
       "      <td>nrlwci</td>\n",
       "      <td>t3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Reposting something I found in r/stocks, basic...</td>\n",
       "      <td>HODL my smooth brained apes üíéüôåüèΩü¶ç</td>\n",
       "      <td>0.92</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              created_utc      id kind   score  \\\n",
       "142  2021-06-03T01:12:52Z  nr1dkn   t3  5367.0   \n",
       "143  2021-06-03T10:15:31Z  nr9zni   t3     2.0   \n",
       "144  2021-06-03T19:35:46Z  nrlwci   t3    10.0   \n",
       "\n",
       "                                              selftext  \\\n",
       "142  I understand that most people in this thread i...   \n",
       "143  **Author**: u/Shark_Bones(**Karma:** 311078, *...   \n",
       "144  Reposting something I found in r/stocks, basic...   \n",
       "\n",
       "                                                 title  upvote_ratio sentiment  \n",
       "142             Beware of what AMC shorts are holding!          0.91   neutral  \n",
       "143  Are we headed for the Mother of All Crashes? H...          0.67  negative  \n",
       "144                   HODL my smooth brained apes üíéüôåüèΩü¶ç          0.92  positive  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[(data['created_utc'] < str(date(2021,6,5))) & (data['created_utc'] > str(date(2021,6,5) - timedelta(7)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "sporting-cement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def get_sentiment_data(data, for_date, window=7):\n",
    "    '''\n",
    "    Input:\n",
    "        for_date: a datetime.date object for the max_date when a post was created\n",
    "        window: how far back to gather data on posts (days)\n",
    "    Output:\n",
    "        1 x 6 dataframe with statistics on sentiment for that time interval\n",
    "    '''\n",
    "    window_data = data.loc[(data['created_utc'] < str(for_date)) & (data['created_utc'] > str(for_date - timedelta(window)))]\n",
    "    s = window_data['sentiment']\n",
    "    pos_count, pos_score = s[s == 'positive'].count(), window_data['score'][s == 'positive'].sum()\n",
    "    neut_count, neut_score = s[s == 'neutral'].count(), window_data['score'][s == 'neutral'].sum()\n",
    "    neg_count, neg_score = s[s == 'negative'].count(), window_data['score'][s == 'negative'].sum()\n",
    "    \n",
    "    tot = pos_count + neut_count + neg_count\n",
    "    if tot == 0:\n",
    "        return [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    pos_p = pos_count / tot\n",
    "    neut_p = neut_count / tot\n",
    "    neg_p = neg_count / tot\n",
    "\n",
    "    cols = ['Percent Positive', 'Percent Neutral', 'Percent Negative', 'Positive Score', 'Neutral Score', 'Negative Score']\n",
    "    stats = np.array([pos_p, neut_p, neg_p, pos_score, neut_score, neg_score])\n",
    "#     out = pd.DataFrame(data=stats.reshape(1,-1), index=[for_date], columns=cols)\n",
    "    out = [pos_p, neut_p, neg_p, pos_score, neut_score, neg_score]\n",
    "    return out\n",
    "\n",
    "get_sentiment_data(data, date(2021,5,12))#datetime.strptime('2021-05-12T00:00:00', '%Y-%m-%dT%H:%M:%S').date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "rolled-inspection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>kind</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>upvote_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-04-17T13:14:42Z</td>\n",
       "      <td>1ilb8</td>\n",
       "      <td>t3</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>ALLIRA COHRS</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-11T16:58:42Z</td>\n",
       "      <td>f0ax0</td>\n",
       "      <td>t3</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>COHR, ENZ, BIIB, PWRM, PCLN - CRWEWallstreet.c...</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-09-25T21:01:26Z</td>\n",
       "      <td>1n4ph5</td>\n",
       "      <td>t3</td>\n",
       "      <td>9.0</td>\n",
       "      <td></td>\n",
       "      <td>WIPO Approves 15 New Observers, Including DNDi...</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-09-25T21:18:42Z</td>\n",
       "      <td>1n4qvr</td>\n",
       "      <td>t3</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td>WIPO Approves 15 New Observers, Including DNDi...</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-10-26T18:04:28Z</td>\n",
       "      <td>3qb4zy</td>\n",
       "      <td>t3</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>Relationship between Blood Myostatin Levels an...</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2021-11-29T11:54:46Z</td>\n",
       "      <td>r4u8n3</td>\n",
       "      <td>t3</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>$COHR Awaiting short signal. Algo Trading Idea...</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2021-11-30T19:17:00Z</td>\n",
       "      <td>r5uymx</td>\n",
       "      <td>t3</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>$COHR Waiting for Short signal.</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>2021-12-03T18:14:00Z</td>\n",
       "      <td>r85dcd</td>\n",
       "      <td>t3</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>$COHR Awaiting Short Signal. Stock Trading Ide...</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>2021-12-03T18:17:48Z</td>\n",
       "      <td>r85gfk</td>\n",
       "      <td>t3</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>$COHR Awaiting Short Signal. Stock Trading Ide...</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2021-12-10T04:56:38Z</td>\n",
       "      <td>rd0pmj</td>\n",
       "      <td>t3</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>Stock Pattern Cup-and-Handle COHR on November ...</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              created_utc      id kind  score selftext  \\\n",
       "0    2007-04-17T13:14:42Z   1ilb8   t3    0.0            \n",
       "1    2011-01-11T16:58:42Z   f0ax0   t3    0.0            \n",
       "2    2013-09-25T21:01:26Z  1n4ph5   t3    9.0            \n",
       "3    2013-09-25T21:18:42Z  1n4qvr   t3    2.0            \n",
       "4    2015-10-26T18:04:28Z  3qb4zy   t3    1.0            \n",
       "..                    ...     ...  ...    ...      ...   \n",
       "238  2021-11-29T11:54:46Z  r4u8n3   t3    1.0            \n",
       "239  2021-11-30T19:17:00Z  r5uymx   t3    1.0            \n",
       "240  2021-12-03T18:14:00Z  r85dcd   t3    1.0            \n",
       "241  2021-12-03T18:17:48Z  r85gfk   t3    1.0            \n",
       "242  2021-12-10T04:56:38Z  rd0pmj   t3    1.0            \n",
       "\n",
       "                                                 title  upvote_ratio  \n",
       "0                                         ALLIRA COHRS          0.50  \n",
       "1    COHR, ENZ, BIIB, PWRM, PCLN - CRWEWallstreet.c...          0.50  \n",
       "2    WIPO Approves 15 New Observers, Including DNDi...          0.99  \n",
       "3    WIPO Approves 15 New Observers, Including DNDi...          0.63  \n",
       "4    Relationship between Blood Myostatin Levels an...          1.00  \n",
       "..                                                 ...           ...  \n",
       "238  $COHR Awaiting short signal. Algo Trading Idea...          1.00  \n",
       "239                    $COHR Waiting for Short signal.          1.00  \n",
       "240  $COHR Awaiting Short Signal. Stock Trading Ide...          1.00  \n",
       "241  $COHR Awaiting Short Signal. Stock Trading Ide...          1.00  \n",
       "242  Stock Pattern Cup-and-Handle COHR on November ...          1.00  \n",
       "\n",
       "[243 rows x 7 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a peek at our data\n",
    "data = data.sort_values(by=['created_utc'], ignore_index=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "damaged-course",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>kind</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-04-17T13:14:42Z</td>\n",
       "      <td>1ilb8</td>\n",
       "      <td>t3</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>ALLIRA COHRS</td>\n",
       "      <td>0.50</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-11T16:58:42Z</td>\n",
       "      <td>f0ax0</td>\n",
       "      <td>t3</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>COHR, ENZ, BIIB, PWRM, PCLN - CRWEWallstreet.c...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-09-25T21:01:26Z</td>\n",
       "      <td>1n4ph5</td>\n",
       "      <td>t3</td>\n",
       "      <td>9.0</td>\n",
       "      <td></td>\n",
       "      <td>WIPO Approves 15 New Observers, Including DNDi...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-09-25T21:18:42Z</td>\n",
       "      <td>1n4qvr</td>\n",
       "      <td>t3</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td>WIPO Approves 15 New Observers, Including DNDi...</td>\n",
       "      <td>0.63</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-10-26T18:04:28Z</td>\n",
       "      <td>3qb4zy</td>\n",
       "      <td>t3</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>Relationship between Blood Myostatin Levels an...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2021-11-29T11:54:46Z</td>\n",
       "      <td>r4u8n3</td>\n",
       "      <td>t3</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>$COHR Awaiting short signal. Algo Trading Idea...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2021-11-30T19:17:00Z</td>\n",
       "      <td>r5uymx</td>\n",
       "      <td>t3</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>$COHR Waiting for Short signal.</td>\n",
       "      <td>1.00</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>2021-12-03T18:14:00Z</td>\n",
       "      <td>r85dcd</td>\n",
       "      <td>t3</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>$COHR Awaiting Short Signal. Stock Trading Ide...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>2021-12-03T18:17:48Z</td>\n",
       "      <td>r85gfk</td>\n",
       "      <td>t3</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>$COHR Awaiting Short Signal. Stock Trading Ide...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2021-12-10T04:56:38Z</td>\n",
       "      <td>rd0pmj</td>\n",
       "      <td>t3</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>Stock Pattern Cup-and-Handle COHR on November ...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              created_utc      id kind  score selftext  \\\n",
       "0    2007-04-17T13:14:42Z   1ilb8   t3    0.0            \n",
       "1    2011-01-11T16:58:42Z   f0ax0   t3    0.0            \n",
       "2    2013-09-25T21:01:26Z  1n4ph5   t3    9.0            \n",
       "3    2013-09-25T21:18:42Z  1n4qvr   t3    2.0            \n",
       "4    2015-10-26T18:04:28Z  3qb4zy   t3    1.0            \n",
       "..                    ...     ...  ...    ...      ...   \n",
       "238  2021-11-29T11:54:46Z  r4u8n3   t3    1.0            \n",
       "239  2021-11-30T19:17:00Z  r5uymx   t3    1.0            \n",
       "240  2021-12-03T18:14:00Z  r85dcd   t3    1.0            \n",
       "241  2021-12-03T18:17:48Z  r85gfk   t3    1.0            \n",
       "242  2021-12-10T04:56:38Z  rd0pmj   t3    1.0            \n",
       "\n",
       "                                                 title  upvote_ratio sentiment  \n",
       "0                                         ALLIRA COHRS          0.50   neutral  \n",
       "1    COHR, ENZ, BIIB, PWRM, PCLN - CRWEWallstreet.c...          0.50   neutral  \n",
       "2    WIPO Approves 15 New Observers, Including DNDi...          0.99  positive  \n",
       "3    WIPO Approves 15 New Observers, Including DNDi...          0.63  positive  \n",
       "4    Relationship between Blood Myostatin Levels an...          1.00   neutral  \n",
       "..                                                 ...           ...       ...  \n",
       "238  $COHR Awaiting short signal. Algo Trading Idea...          1.00   neutral  \n",
       "239                    $COHR Waiting for Short signal.          1.00   neutral  \n",
       "240  $COHR Awaiting Short Signal. Stock Trading Ide...          1.00   neutral  \n",
       "241  $COHR Awaiting Short Signal. Stock Trading Ide...          1.00   neutral  \n",
       "242  Stock Pattern Cup-and-Handle COHR on November ...          1.00   neutral  \n",
       "\n",
       "[243 rows x 8 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'] = data['title'].apply(get_sentiment)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "interracial-vector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positives for this time frame: count=32, score=1475.0\n",
      "neutral for this time frame: count=206, score=7334.0\n",
      "negatives for this time frame: count=5, score=24.0\n"
     ]
    }
   ],
   "source": [
    "s = data['sentiment']\n",
    "pos_count, pos_score = s[s == 'positive'].count(), data['score'][s == 'positive'].sum()\n",
    "neut_count, neut_score = s[s == 'neutral'].count(), data['score'][s == 'neutral'].sum()\n",
    "neg_count, neg_score = s[s == 'negative'].count(), data['score'][s == 'negative'].sum()\n",
    "print('positives for this time frame: count={}, score={}'.format(pos_count, pos_score))\n",
    "print('neutral for this time frame: count={}, score={}'.format(neut_count, neut_score))\n",
    "print('negatives for this time frame: count={}, score={}'.format(neg_count, neg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fallen-firewall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos: 0.13168724279835392 Neut: 0.8477366255144033 Neg: 0.0205761316872428\n"
     ]
    }
   ],
   "source": [
    "tot = pos_count + neut_count + neg_count\n",
    "pos_p = pos_count / tot\n",
    "neut_p = neut_count / tot\n",
    "neg_p = neg_count / tot\n",
    "print(\"Pos: {} Neut: {} Neg: {}\".format(pos_p, neut_p, neg_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-progress",
   "metadata": {},
   "source": [
    "#### Sample Output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "characteristic-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cols = ['Percent Positive', 'Percent Neutral', 'Percent Negative', 'Positive Score', 'Neutral Score', 'Negative Score']\n",
    "data = np.array([pos_p, neut_p, neg_p, pos_score, neut_score, neg_score])\n",
    "out = pd.DataFrame(data=data.reshape(1,-1), index=[date(2000,1,1)], columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "juvenile-jordan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percent Positive</th>\n",
       "      <th>Percent Neutral</th>\n",
       "      <th>Percent Negative</th>\n",
       "      <th>Positive Score</th>\n",
       "      <th>Neutral Score</th>\n",
       "      <th>Negative Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>0.131687</td>\n",
       "      <td>0.847737</td>\n",
       "      <td>0.020576</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>7334.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Percent Positive  Percent Neutral  Percent Negative  \\\n",
       "2000-01-01          0.131687         0.847737          0.020576   \n",
       "\n",
       "            Positive Score  Neutral Score  Negative Score  \n",
       "2000-01-01          1475.0         7334.0            24.0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-wrist",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
